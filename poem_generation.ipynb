{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tf_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "#                ----   NLP    ----\n",
        "#           Helper functions for Deep Learning experiments\n",
        "#  Following the course at Udemy\n",
        "#  https://www.udemy.com/course/tensorflow-developer-certificate-machine-learning-zero-to-mastery/\n",
        "#                ------------------\n",
        "############################################################\n",
        "import requests\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow.keras.utils as kerasutils\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "######################################## Getting text corpus\n",
        "\n",
        "# usage:\n",
        "#           text, average_words_number=get_corpus(url=\"https://www.gutenberg.org/cache/epub/38572/pg38572.txt\",\n",
        "#                   get_part=True, start_phrase=\"LOVE SONNETS OF AN\",\n",
        "#                   end_phrase=\"_Now in Press_\" )\n",
        "def get_corpus(url, get_part=True, start_phrase=\"\", end_phrase=\"\"):\n",
        "    \"\"\"\n",
        "    Extracts text from a file located at the provided web address.\n",
        "    :param url: Link to the text file\n",
        "    :param get_part: when True, we get only text located between start_phrase and end_phrase strings\n",
        "    :param start_phrase:\n",
        "    :param end_phrase:\n",
        "    :return: a stripped text string without carriage returns, and the average number of words in line.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = requests.get(url).text\n",
        "    except:\n",
        "        print(\"Can not load the document at: \" + str(url))\n",
        "        return False\n",
        "\n",
        "    if get_part:\n",
        "        start = text.find(start_phrase)  # skip header\n",
        "        end = text.rfind(end_phrase)  # skip extra text at the end\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    # Split text on carriage returns\n",
        "    text = text.split('\\r')\n",
        "\n",
        "    # Strip off new lines and empty spaces from the text\n",
        "    text = [t.strip() for t in text]\n",
        "\n",
        "    average_number_of_words_in_line = round(sum([len(s.split()) for s in text]) / len(text))\n",
        "    return text, average_number_of_words_in_line\n",
        "\n",
        "\n",
        "######################################## Tokenizing text\n",
        "def create_tokenizer(text):\n",
        "    \"\"\"\n",
        "    Returns tokenizer and total words number based on the extracted text.\n",
        "    :param text: a text corpus, extracted and preprocessed with get_corpus()\n",
        "    :return: tokenizer, total words number\n",
        "    \"\"\"\n",
        "    # Please note that I have removed symbols [.,;:] from the default filetr value\n",
        "    # This helps to preserve punctuation to a certain extent\n",
        "    tokenizer = Tokenizer(filters='\"#$%&()*+-/<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "    tokenizer.fit_on_texts(text)\n",
        "\n",
        "    # Total number of words\n",
        "    vocabulary_length = len(tokenizer.word_index) + 1\n",
        "    return tokenizer, vocabulary_length\n",
        "\n",
        "\n",
        "######################################## Padding sequences\n",
        "\n",
        "def pack_sequences(text, tokenizer, total_words_number):\n",
        "  \"\"\"\n",
        "  Based on the corpus of documents and tokenizer, create padded sequences for further prediction task\n",
        "  :param corpus: Text strings\n",
        "  :param tokenizer: tokenizer\n",
        "  :param total_words_number: unique number of words in the corpus\n",
        "  :return: maximum length of sequences, predictors and labels\n",
        "  \"\"\"\n",
        "  # create input sequences using list of tokens\n",
        "  input_sequences = []\n",
        "  for line in text:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i + 1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "  # pad sequences\n",
        "  max_sequence_len = max([len(x) for x in input_sequences])\n",
        "  input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "  # create predictors and labels\n",
        "  predictors, labels = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "  labels = kerasutils.to_categorical(labels, num_classes=total_words_number)\n",
        "  return max_sequence_len, predictors, labels\n",
        "\n",
        "\n",
        "######################################## Create Keras Sequential model with word embeddings\n",
        "def create_model(vocabulary_length, sequence_length):\n",
        "  model = Sequential()\n",
        "  model.add(\n",
        "        Embedding(input_dim=vocabulary_length, output_dim=100, input_length=sequence_length - 1))\n",
        "  model.add(Bidirectional(LSTM(150, return_sequences=False))) \n",
        "  model.add(Dense(vocabulary_length, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def write_poem(model, tokenizer, max_sequence_length, seed_text=\"The Moon and Sun\", next_words=6, paragraphs=3):\n",
        "    \"\"\"\n",
        "    Uses fitted text generating Keras Sequential model to write a poem.\n",
        "    :param model: Keras sequential model, fitted to a text corpus\n",
        "    :param tokenizer: Tokenizer\n",
        "    :param max_sequence_length: Maximum length of text sequences\n",
        "    :param seed_text: a text sring to start poem generation\n",
        "    :param next_words: Number of words in a sentence\n",
        "    :param paragraphs: Number of paragraphs in the generated poem\n",
        "    :return: text of the generated poem\n",
        "    \"\"\"\n",
        "    poem = seed_text.capitalize() + \"\\n\\n\"\n",
        "    while paragraphs > 0:\n",
        "        paragraph = \"\"\n",
        "        for word_number in range(next_words):\n",
        "            sentence = \"\\n\"\n",
        "            for _ in range(next_words):\n",
        "                token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "                token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "                predicted = model.predict(token_list)\n",
        "                predicted = np.argmax(predicted, axis=-1)\n",
        "                output_word = \"\"\n",
        "                for word, index in tokenizer.word_index.items():\n",
        "                    if index == predicted:\n",
        "                        output_word = word\n",
        "                        break\n",
        "                seed_text += \" \" + output_word\n",
        "                sentence += \" \" + output_word\n",
        "            if word_number < next_words:\n",
        "                paragraph += sentence.strip().capitalize() + \"\\n\"\n",
        "            seed_text = output_word\n",
        "        seed_text = sentence\n",
        "        poem += paragraph + \"\\n\"\n",
        "        paragraphs -= 1\n",
        "\n",
        "    print(poem)\n",
        "    return poem"
      ],
      "metadata": {
        "id": "HC-hzzcQ1lDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting and preprocessing a text corpus\n",
        "text, average_words_number = get_corpus(url=\"https://www.gutenberg.org/cache/epub/45470/pg45470.txt\", get_part=True, start_phrase=\"THE SHINING HOURS\",\n",
        "                    end_phrase=\"End of the Project Gutenberg EBook\" )\n"
      ],
      "metadata": {
        "id": "w05bIoQy1nt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tguCISF4HD-",
        "outputId": "fc2d96d3-2466-443e-e849-92bb2286ac9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffThe Project Gutenberg EBook of The Love Poems, by Ã‰mile Verhaeren',\n",
              " '',\n",
              " 'This eBook is for the use of anyone anywhere at no cost and with',\n",
              " 'almost no restrictions whatsoever.  You may copy it, give it away or',\n",
              " 're-use it under the terms of the Project Gutenberg License included',\n",
              " 'with this eBook or online at www.gutenberg.org/license',\n",
              " '',\n",
              " '',\n",
              " 'Title: The Love Poems',\n",
              " \"(From Les Heures claires, Les Heures d'aprÃ¨s-midi, Les Heures du Soir)\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_words_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHS1KTcM4loI",
        "outputId": "3eab526c-8b81-4e32-eb6d-caf8f68716dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the extracted text\n",
        "tokenizer, vocabulary_length =  create_tokenizer(text)\n"
      ],
      "metadata": {
        "id": "Q7kUEzS53ioO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulary_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cCLeAvn5yAg",
        "outputId": "8fd8f150-dfb2-49eb-a8dd-f7f07180ae2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad text sequences\n",
        "sequence_length, predictors, labels = pack_sequences(text, tokenizer, vocabulary_length)\n"
      ],
      "metadata": {
        "id": "8vjZ_4RM3krG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdATnPlY9iDC",
        "outputId": "fc02407c-8a63-41a1-ffa7-fbee7065f108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8YWipbD9O_R",
        "outputId": "0cf9b549-792c-4a39-dddd-5fa87b1a1610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poem Writing"
      ],
      "metadata": {
        "id": "bB5HKb5fXfI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create and the poem generating model\n",
        "poems = create_model(vocabulary_length, sequence_length)\n"
      ],
      "metadata": {
        "id": "1TMfvzVO3m-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "print(poems.summary())\n",
        "\n"
      ],
      "metadata": {
        "id": "L_lOk3xu3p4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecee1a2-7e52-443a-ed84-a1f5aa5d66d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 14, 100)           371400    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 300)              301200    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3714)              1117914   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,790,514\n",
            "Trainable params: 1,790,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/edaehn/deep_learning_notebooks/main/helpers.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nypjnBD88FS8",
        "outputId": "573cc639-4625-4d17-e1a3-a778bd142ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-31 11:10:44--  https://raw.githubusercontent.com/edaehn/deep_learning_notebooks/main/helpers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38519 (38K) [text/plain]\n",
            "Saving to: â€˜helpers.pyâ€™\n",
            "\n",
            "\rhelpers.py            0%[                    ]       0  --.-KB/s               \rhelpers.py          100%[===================>]  37.62K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-07-31 11:10:44 (11.3 MB/s) - â€˜helpers.pyâ€™ saved [38519/38519]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helpers import create_early_stopping_callback"
      ],
      "metadata": {
        "id": "GdPSt5hs8aS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = poems.fit(predictors, \n",
        "                    labels, \n",
        "                    epochs=57, \n",
        "                    callbacks=[create_early_stopping_callback()],\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ_3KpMI8hXx",
        "outputId": "e4c6f8d8-ad25-41fb-c876-352f34267988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/57\n",
            "451/451 [==============================] - 33s 73ms/step - loss: 6.3716 - accuracy: 0.0804\n",
            "Epoch 2/57\n",
            "451/451 [==============================] - 39s 86ms/step - loss: 6.0139 - accuracy: 0.1007\n",
            "Epoch 3/57\n",
            "451/451 [==============================] - 35s 77ms/step - loss: 5.6633 - accuracy: 0.1250\n",
            "Epoch 4/57\n",
            "451/451 [==============================] - 33s 74ms/step - loss: 5.2938 - accuracy: 0.1454\n",
            "Epoch 5/57\n",
            "451/451 [==============================] - 30s 68ms/step - loss: 4.8788 - accuracy: 0.1625\n",
            "Epoch 6/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 4.4340 - accuracy: 0.1866\n",
            "Epoch 7/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 3.9822 - accuracy: 0.2189\n",
            "Epoch 8/57\n",
            "451/451 [==============================] - 31s 68ms/step - loss: 3.5353 - accuracy: 0.2729\n",
            "Epoch 9/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 3.1010 - accuracy: 0.3394\n",
            "Epoch 10/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 2.7096 - accuracy: 0.4112\n",
            "Epoch 11/57\n",
            "451/451 [==============================] - 31s 69ms/step - loss: 2.3603 - accuracy: 0.4815\n",
            "Epoch 12/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 2.0644 - accuracy: 0.5433\n",
            "Epoch 13/57\n",
            "451/451 [==============================] - 35s 78ms/step - loss: 1.8089 - accuracy: 0.5982\n",
            "Epoch 14/57\n",
            "451/451 [==============================] - 33s 73ms/step - loss: 1.5897 - accuracy: 0.6483\n",
            "Epoch 15/57\n",
            "451/451 [==============================] - 33s 72ms/step - loss: 1.4058 - accuracy: 0.6898\n",
            "Epoch 16/57\n",
            "451/451 [==============================] - 34s 74ms/step - loss: 1.2458 - accuracy: 0.7218\n",
            "Epoch 17/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 1.1083 - accuracy: 0.7582\n",
            "Epoch 18/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 0.9844 - accuracy: 0.7838\n",
            "Epoch 19/57\n",
            "451/451 [==============================] - 42s 92ms/step - loss: 0.8872 - accuracy: 0.8079\n",
            "Epoch 20/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.7943 - accuracy: 0.8301\n",
            "Epoch 21/57\n",
            "451/451 [==============================] - 39s 87ms/step - loss: 0.7229 - accuracy: 0.8448\n",
            "Epoch 22/57\n",
            "451/451 [==============================] - 39s 87ms/step - loss: 0.6575 - accuracy: 0.8573\n",
            "Epoch 23/57\n",
            "451/451 [==============================] - 31s 69ms/step - loss: 0.6056 - accuracy: 0.8670\n",
            "Epoch 24/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 0.5648 - accuracy: 0.8725\n",
            "Epoch 25/57\n",
            "451/451 [==============================] - 31s 68ms/step - loss: 0.5339 - accuracy: 0.8773\n",
            "Epoch 26/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.5005 - accuracy: 0.8856\n",
            "Epoch 27/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 0.4769 - accuracy: 0.8875\n",
            "Epoch 28/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.4491 - accuracy: 0.8928\n",
            "Epoch 29/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 0.4366 - accuracy: 0.8942\n",
            "Epoch 30/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.4295 - accuracy: 0.8933\n",
            "Epoch 31/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.4133 - accuracy: 0.8965\n",
            "Epoch 32/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.3982 - accuracy: 0.8972\n",
            "Epoch 33/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 0.3912 - accuracy: 0.8980\n",
            "Epoch 34/57\n",
            "451/451 [==============================] - 30s 67ms/step - loss: 0.3881 - accuracy: 0.8974\n",
            "Epoch 35/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.3839 - accuracy: 0.9007\n",
            "Epoch 36/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.3719 - accuracy: 0.8992\n",
            "Epoch 37/57\n",
            "451/451 [==============================] - 29s 65ms/step - loss: 0.3677 - accuracy: 0.9006\n",
            "Epoch 38/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.3696 - accuracy: 0.8999\n",
            "Epoch 39/57\n",
            "451/451 [==============================] - 30s 65ms/step - loss: 0.3650 - accuracy: 0.9004\n",
            "Epoch 40/57\n",
            "451/451 [==============================] - 29s 65ms/step - loss: 0.3531 - accuracy: 0.9027\n",
            "Epoch 41/57\n",
            "451/451 [==============================] - 29s 65ms/step - loss: 0.3543 - accuracy: 0.9009\n",
            "Epoch 42/57\n",
            "451/451 [==============================] - 30s 65ms/step - loss: 0.3523 - accuracy: 0.9019\n",
            "Epoch 43/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.3483 - accuracy: 0.9022\n",
            "Epoch 44/57\n",
            "451/451 [==============================] - 29s 65ms/step - loss: 0.3461 - accuracy: 0.9023\n",
            "Epoch 45/57\n",
            "451/451 [==============================] - 29s 65ms/step - loss: 0.3433 - accuracy: 0.9019\n",
            "Epoch 46/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.3400 - accuracy: 0.9011\n",
            "Epoch 47/57\n",
            "451/451 [==============================] - 29s 65ms/step - loss: 0.3297 - accuracy: 0.9042\n",
            "Epoch 48/57\n",
            "451/451 [==============================] - 30s 66ms/step - loss: 0.3307 - accuracy: 0.9040\n",
            "Epoch 49/57\n",
            "451/451 [==============================] - 30s 65ms/step - loss: 0.3309 - accuracy: 0.9038\n",
            "Epoch 49: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poems.save(\"poems\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZzFl8LY3zw4",
        "outputId": "94c72160-5f35-4a0d-f988-1f1f741056a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: poems/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: poems/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe20521ce10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe205059490> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !zip -r poems.zip poems"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84pZEJ-U4EGX",
        "outputId": "2e51e55b-bc78-478a-be76-dc5168a491e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: poems/ (stored 0%)\n",
            "  adding: poems/keras_metadata.pb (deflated 89%)\n",
            "  adding: poems/variables/ (stored 0%)\n",
            "  adding: poems/variables/variables.index (deflated 64%)\n",
            "  adding: poems/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: poems/assets/ (stored 0%)\n",
            "  adding: poems/saved_model.pb (deflated 91%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Prediction on Layers"
      ],
      "metadata": {
        "id": "fZTio7lVa4Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model layers\n",
        "poems.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M8E8wVQfFK7",
        "outputId": "efd76db0-f522-4677-de10-e498d8d02cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.embeddings.Embedding at 0x7fe20511a650>,\n",
              " <keras.layers.wrappers.Bidirectional at 0x7fe205120c90>,\n",
              " <keras.layers.core.dense.Dense at 0x7fe2011fab90>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "\n",
        "# Text for predictions\n",
        "seed_text = \"Call me\"\n",
        "\n",
        "def preprocess(seed_text):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=14, padding='pre')\n",
        "  return token_list\n",
        "\n",
        "\n",
        "print(\"Model outputs on each layer\")\n",
        "\n",
        "for i in range(0, len(poems.layers)):\n",
        "    model = Model(poems.layers[0].input, poems.layers[i].output)\n",
        "    output = model.predict(preprocess(seed_text))\n",
        "    print(f\"======= {i}: {poems.layers[i]} ========\")\n",
        "    print(f\"{output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPYBHoA6ezue",
        "outputId": "eca304ff-8938-4e1d-fd11-346028d231fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model outputs on each layer\n",
            "======= 0: <keras.layers.embeddings.Embedding object at 0x7fc388b54a90> ========\n",
            "[[[-0.02469707  0.07959411  0.06904098 ... -0.10707945 -0.01648859\n",
            "   -0.06807811]\n",
            "  [-0.02469707  0.07959411  0.06904098 ... -0.10707945 -0.01648859\n",
            "   -0.06807811]\n",
            "  [-0.02469707  0.07959411  0.06904098 ... -0.10707945 -0.01648859\n",
            "   -0.06807811]\n",
            "  ...\n",
            "  [-0.02469707  0.07959411  0.06904098 ... -0.10707945 -0.01648859\n",
            "   -0.06807811]\n",
            "  [-0.04088492 -0.03654863 -0.04958899 ... -0.02871312 -0.04795657\n",
            "    0.03860951]\n",
            "  [ 0.12126409  0.04980833  0.04991504 ... -0.10262618  0.04374539\n",
            "    0.04749   ]]]\n",
            "======= 1: <keras.layers.wrappers.Bidirectional object at 0x7fc36607a690> ========\n",
            "[[ 4.46121156e-01  8.96401405e-01 -6.79003716e-01  9.80030835e-01\n",
            "  -8.23857725e-01  1.31664574e-02  3.99768203e-02  1.13104582e-02\n",
            "   4.80327010e-03  7.81018376e-01 -1.14573717e-01  3.75620127e-02\n",
            "  -5.36459982e-02 -7.54609883e-01  4.04699445e-02  1.86996758e-01\n",
            "  -8.20412874e-01  7.18474090e-01 -1.91462815e-01 -8.11813474e-01\n",
            "  -7.28182375e-01  8.33959222e-01  4.20906059e-02  2.05678828e-02\n",
            "  -2.29923278e-01  2.36079752e-01 -6.49458349e-01  4.14602518e-01\n",
            "  -2.15026401e-02  2.89213091e-01 -1.02820873e-01  1.27935767e-01\n",
            "  -8.67722631e-01 -9.97471213e-01  6.57943964e-01 -9.93554354e-01\n",
            "   8.56430411e-01 -3.75514239e-01 -6.40511215e-02 -1.88451052e-01\n",
            "   7.06216037e-01 -1.07713759e-01  6.52352571e-01  1.44025326e-01\n",
            "  -9.58081245e-01  9.02721524e-01 -5.65882564e-01 -9.55473900e-01\n",
            "   2.57796556e-01 -1.22324109e-01 -5.68897426e-02  7.64064193e-02\n",
            "   4.65691060e-01 -6.96531892e-01  6.38117790e-01  7.16957450e-02\n",
            "   3.75276655e-01  9.14129019e-02  7.66748846e-01 -7.55758703e-01\n",
            "   8.03742334e-02  8.76823843e-01 -1.39249116e-01  4.21565920e-01\n",
            "  -6.83687508e-01  7.33720660e-01  4.50736791e-01 -9.54050124e-01\n",
            "   1.67549849e-01 -9.84961689e-01 -1.45263467e-02  6.36664987e-01\n",
            "  -1.46753490e-02  4.32552218e-01 -8.15212131e-02 -8.06738973e-01\n",
            "  -7.36621439e-01  7.59483695e-01  9.99824047e-01 -7.56395936e-01\n",
            "  -4.73551959e-01  4.59151149e-01 -1.71762910e-02 -4.98603582e-02\n",
            "   7.98590183e-02  7.95602083e-01  6.93644464e-01  6.70176983e-01\n",
            "  -7.23686337e-01 -5.76537371e-01  7.54384160e-01 -7.08227158e-01\n",
            "  -3.67164053e-02  4.32394385e-01  2.52972424e-01 -3.27773780e-01\n",
            "  -5.94611503e-02 -3.31745714e-01  8.34432483e-01  1.85704120e-02\n",
            "   7.78994381e-01 -3.89222860e-01 -4.93003517e-01 -4.15201522e-02\n",
            "  -8.59071493e-01  6.26289248e-01 -2.39984930e-01 -1.94959890e-03\n",
            "   7.84591734e-02 -3.79035771e-02  8.73195305e-02  7.31608868e-02\n",
            "  -7.63907731e-01 -8.73578906e-01  7.60069966e-01 -5.77231765e-01\n",
            "  -7.37671494e-01 -1.03437258e-02  7.86661625e-01 -7.35724926e-01\n",
            "   9.56578910e-01 -9.23976719e-01  3.96547914e-01  2.54024956e-02\n",
            "  -5.81091642e-03 -6.22753441e-01  6.43160880e-01 -6.67177439e-02\n",
            "  -9.43642497e-01  4.42526251e-01  7.81691134e-01 -1.61296129e-02\n",
            "   7.55565882e-01  1.80020602e-03  2.50762720e-02 -9.93584692e-01\n",
            "   3.60514700e-01 -1.11534536e-01  9.73364472e-01  1.28800020e-01\n",
            "   8.11576784e-01  3.08418185e-01  9.99314249e-01  7.10563362e-01\n",
            "   2.50259906e-01  2.67452896e-02  1.57726794e-01  5.47965705e-01\n",
            "  -1.09393060e-01 -5.20530641e-01 -3.52521449e-01  3.66611034e-02\n",
            "  -9.63539839e-01  2.22456791e-02  1.33951733e-04  3.54732969e-03\n",
            "  -4.99962986e-01  3.04283982e-04  8.59992564e-01  9.49827880e-02\n",
            "  -2.12065969e-02  3.38219196e-01  7.29061887e-02  9.46197748e-01\n",
            "  -9.42342818e-01 -9.16827202e-01  1.69850525e-03  8.73607635e-01\n",
            "   8.20674598e-01 -9.12442803e-01  9.33405995e-01 -2.68222182e-03\n",
            "   2.52486183e-03  8.71156156e-01 -9.73685086e-01 -4.10334207e-03\n",
            "  -9.58127975e-01  4.56574291e-01  9.85799789e-01 -2.39025995e-01\n",
            "  -8.77378732e-02 -3.02790403e-02 -5.13376474e-01  9.96418357e-01\n",
            "  -9.16622341e-01 -4.62078124e-01  8.83412957e-02  5.81574044e-04\n",
            "  -2.17129856e-01  1.08589372e-02 -3.70489098e-02  6.21751189e-01\n",
            "   1.37258232e-01 -9.19440448e-01  2.24684641e-01 -1.51107889e-02\n",
            "  -1.41397253e-01  5.30469872e-04 -5.38133600e-06 -2.41506379e-02\n",
            "   9.37458754e-01  9.93674994e-01 -4.25968975e-01  1.64644443e-04\n",
            "  -9.61574852e-01 -1.75333885e-03  1.26725927e-01  9.86651599e-01\n",
            "  -9.12691057e-01 -5.72855175e-01 -9.50557351e-01 -1.96066305e-01\n",
            "   7.55876652e-04 -4.87340763e-02  2.98979064e-03 -8.45768750e-01\n",
            "   1.60427406e-01 -8.45293641e-01 -1.49785792e-02 -2.99102685e-04\n",
            "   1.31269932e-01  1.40863927e-02  7.86818191e-03  8.50028813e-01\n",
            "  -1.96920261e-02  5.89190185e-01  1.31078232e-02 -8.33507180e-01\n",
            "  -3.31080675e-01 -1.83762461e-01 -1.50514385e-02  1.68142952e-02\n",
            "  -9.58604991e-01 -6.24459870e-02 -7.73304999e-01 -6.14375055e-01\n",
            "   7.35360198e-03  3.21748480e-03  9.28044096e-02 -7.22706854e-01\n",
            "   5.05687475e-01  3.42809525e-03  6.25907183e-01 -4.49915409e-01\n",
            "  -9.58559096e-01  3.06524392e-02  2.70145293e-02 -7.76359141e-01\n",
            "  -7.23399341e-01 -8.97283852e-01  3.44402669e-03 -1.12402746e-02\n",
            "  -2.73411751e-01  2.70295329e-03  9.71824944e-01 -2.14284480e-01\n",
            "  -9.87124324e-01  6.17315769e-01 -3.59269674e-03 -9.16849911e-01\n",
            "  -5.77521443e-01  2.41398774e-02 -4.87308472e-01 -1.82539076e-01\n",
            "  -6.55181944e-01 -9.79292274e-01  1.61778342e-04 -8.79465640e-01\n",
            "   3.39321971e-01  9.09185588e-01 -1.27597926e-02  9.33887482e-01\n",
            "  -7.64853060e-01 -9.61851031e-02  6.16466044e-04  6.63849351e-04\n",
            "   1.40733377e-03  5.13201859e-03  9.54378068e-01 -2.50964127e-02\n",
            "  -8.36366117e-01 -7.76531935e-01 -8.67655396e-01 -9.77285862e-01\n",
            "   2.64110751e-02  1.18871830e-01 -3.22806537e-02  2.88048908e-02\n",
            "  -8.47944011e-06 -6.28059566e-01 -9.04694915e-01  3.02716368e-03\n",
            "  -9.24580216e-01  9.74293888e-01  2.93218793e-04 -1.61213626e-04\n",
            "  -3.00614744e-01  1.82940892e-03 -1.71574159e-03 -6.29104972e-01]]\n",
            "======= 2: <keras.layers.core.dense.Dense object at 0x7fc3660e1a10> ========\n",
            "[[6.6530847e-10 2.1849542e-07 6.6835957e-05 ... 3.3558798e-11\n",
            "  6.6870270e-10 1.8824033e-10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def next_word(predicted):\n",
        "  predicted = np.argmax(predicted, axis=-1)\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "       return word\n",
        "  return \"\"\n",
        "\n",
        "def predict_next_word(seed_text):\n",
        "  predicted = poems.predict(preprocess(seed_text))\n",
        "  return next_word(predicted)"
      ],
      "metadata": {
        "id": "m86tOEwbmCJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9MVvyDhjiEP",
        "outputId": "be879222-47c5-4629-ef43-cce05a41ebc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.7531819e-07, 2.4485288e-02, 4.9533878e-02, ..., 3.7681966e-05,\n",
              "        3.7684080e-07, 1.6513543e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Call me\"\n",
        "next = predict_next_word(seed_text)\n",
        "print(next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2it5X6EigHP",
        "outputId": "94276b70-5b4e-4d3b-a194-0e07c1fe4748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "than\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PPQ_s1qk5QH",
        "outputId": "653e6656-4a4f-4ebd-dfbd-120014cdd279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 7):\n",
        "  next = predict_next_word(seed_text)\n",
        "  seed_text = seed_text + \" \" + next\n",
        "  print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E1NSyLKkfVu",
        "outputId": "04da3f2d-d3a1-485e-bcfa-b31679e72c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Call me than\n",
            "Call me than was\n",
            "Call me than was as\n",
            "Call me than was as our\n",
            "Call me than was as our love.\n",
            "Call me than was as our love. house\n",
            "Call me than was as our love. house in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate poetry\n",
        "write_poem(poems, tokenizer, 15, seed_text=\"Shine in the darkness\", next_words=5, paragraphs=3)\n"
      ],
      "metadata": {
        "id": "ca2Ls2ND3sih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "671d5f2f-852c-429d-97fd-e3c98fd411f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shine in the darkness\n",
            "\n",
            "And the surface other and\n",
            "The garden and the orchard.\n",
            "As creation of derivative works,\n",
            "And the medium on which\n",
            "To gaze on the day\n",
            "\n",
            "Possessed with flames on the\n",
            "Same terrors, the same happinesses,\n",
            "The days of our paths;\n",
            "The day when i had\n",
            "You not, each hour of\n",
            "\n",
            "The deep and chilled they\n",
            "Are there beneath their roof,\n",
            "Monstrous than the divine hour\n",
            "Is unique and sanctified with\n",
            "This ebook or online at\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Shine in the darkness\\n\\nAnd the surface other and\\nThe garden and the orchard.\\nAs creation of derivative works,\\nAnd the medium on which\\nTo gaze on the day\\n\\nPossessed with flames on the\\nSame terrors, the same happinesses,\\nThe days of our paths;\\nThe day when i had\\nYou not, each hour of\\n\\nThe deep and chilled they\\nAre there beneath their roof,\\nMonstrous than the divine hour\\nIs unique and sanctified with\\nThis ebook or online at\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate poetry\n",
        "write_poem(poems, tokenizer, 15, seed_text=\"Winter Rose\", next_words=4, paragraphs=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "-7NQDAq1N8Do",
        "outputId": "3aaa9cbd-ed4b-48ba-d6a5-6988ea7a2d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winter rose\n",
            "\n",
            "On measure your radiant\n",
            "Pond, the goldfish like\n",
            "Those who go towards\n",
            "Its chair of weariness.\n",
            "\n",
            "Girt with roses that\n",
            "The happiness that hovers\n",
            "Because of our thoughts.\n",
            "As creation of derivative\n",
            "\n",
            "Works, reports, performances and\n",
            "The garden and the\n",
            "Same terrors, the same\n",
            "Branch that suspends and\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Winter rose\\n\\nOn measure your radiant\\nPond, the goldfish like\\nThose who go towards\\nIts chair of weariness.\\n\\nGirt with roses that\\nThe happiness that hovers\\nBecause of our thoughts.\\nAs creation of derivative\\n\\nWorks, reports, performances and\\nThe garden and the\\nSame terrors, the same\\nBranch that suspends and\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}